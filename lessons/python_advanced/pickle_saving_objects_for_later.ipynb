{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.7.4 (default, Aug 13 2019, 15:17:50) \n",
      "[Clang 4.0.1 (tags/RELEASE_401/final)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python Version:\", sys.version, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle: Saving Objects for Later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often in data science, we'll create some model or some version of our data and want to use it later. We have many options - we can save the coefficients, or save the data to csv, or...\n",
    "\n",
    "Actually, we don't have that many options. \n",
    "\n",
    "One way to overcome that is to save the python object to a file as a serialized object. That means we convert the entire object to a bunch of bytes, save those bytes into a file, and then have the ability to unpack those bytes back into their original format later. \n",
    "\n",
    "This is done by a module called `pickle`. Let's see it in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "\n",
    "lots_of_noise = {\n",
    "    'CA': [random.randint(0,65) for _ in range(100)],\n",
    "    'IL': [random.randint(0,65) for _ in range(50)],\n",
    "    'NY': [random.randint(0,65) for _ in range(90)],\n",
    "    'WA': [random.randint(0,65) for _ in range(33)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CA': [34, 50, 44, 1, 15, 31, 31, 39, 61, 50, 63, 21, 9, 32, 46, 45, 26, 65, 49, 30, 21, 31, 12, 48, 40, 24, 58, 55, 38, 36, 26, 43, 31, 65, 42, 53, 9, 61, 31, 27, 44, 24, 30, 14, 54, 34, 41, 29, 25, 56, 2, 26, 58, 15, 5, 29, 6, 8, 10, 11, 14, 10, 38, 8, 23, 7, 20, 21, 58, 58, 61, 31, 6, 49, 0, 21, 44, 43, 1, 26, 39, 43, 49, 58, 13, 25, 8, 42, 13, 63, 65, 9, 33, 40, 42, 62, 2, 0, 65, 60], 'IL': [57, 59, 42, 43, 41, 33, 14, 54, 15, 61, 11, 30, 23, 40, 35, 30, 14, 0, 3, 31, 62, 40, 36, 14, 6, 4, 27, 10, 50, 24, 14, 47, 39, 12, 65, 40, 55, 40, 48, 34, 23, 24, 27, 48, 4, 28, 62, 5, 53, 16], 'NY': [55, 46, 12, 36, 25, 63, 2, 12, 3, 55, 16, 60, 48, 8, 23, 23, 17, 19, 58, 60, 48, 35, 20, 13, 41, 41, 41, 8, 45, 40, 2, 30, 48, 11, 16, 50, 38, 38, 25, 11, 64, 55, 29, 61, 32, 43, 0, 46, 0, 14, 13, 11, 46, 42, 4, 11, 27, 18, 0, 12, 6, 51, 19, 63, 35, 28, 42, 8, 4, 35, 5, 6, 44, 29, 19, 20, 59, 4, 62, 20, 20, 48, 46, 6, 65, 49, 15, 6, 47, 60], 'WA': [11, 42, 38, 27, 3, 15, 42, 53, 59, 45, 22, 14, 38, 6, 37, 64, 25, 49, 58, 11, 26, 22, 27, 13, 32, 19, 19, 9, 11, 28, 57, 49, 40]}\n"
     ]
    }
   ],
   "source": [
    "print(lots_of_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable        Type      Data/Info\n",
      "-----------------------------------\n",
      "lots_of_noise   dict      n=4\n",
      "pickle          module    <module 'pickle' from '/U<...>lib/python3.7/pickle.py'>\n",
      "random          module    <module 'random' from '/U<...>lib/python3.7/random.py'>\n",
      "sys             module    <module 'sys' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see in this `whos` command that the object `lots_of_noise` exists and is a `dict` with 4 keys. Nice. Now let's look at our file system and verify that there isn't a file called `noise.pickle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advanced_python_datatypes.ipynb       my_dataframe.pickle\r\n",
      "deep_and_shallow_copy.ipynb           noise.pickle\r\n",
      "\u001b[1m\u001b[36mdeep_copy_demo\u001b[m\u001b[m                        pickle_saving_objects_for_later.ipynb\r\n",
      "instructor_guide_week1_day4.md        readme.md\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advanced_python_datatypes.ipynb        my_dataframe.pickle\r\n",
      "deep_and_shallow_copy.ipynb            noise.pickle\r\n",
      "\u001b[1m\u001b[36mdeep_copy_demo\u001b[m\u001b[m/                        pickle_saving_objects_for_later.ipynb\r\n",
      "instructor_guide_week1_day4.md         readme.md\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now we're ready to create a file and write the bytes to it. To do this with `pickle`, we use python's read-write streamer `open` and create a writable-binary (`wb`) file. We'll then use `pickle.dump` to put an object into that file as a string of bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('noise.pickle', 'wb') as to_write:\n",
    "    pickle.dump(lots_of_noise, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's delete `lots_of_noise` and prove to ourselves it doesn't exist in Python's memory anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del lots_of_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lots_of_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lovely. It's dead forever. Or is it?\n",
    "\n",
    "Let's open that `noise.pickle` file with read-binary (`rb`) mode. Then we'll ask pickle to retrieve the file with `pickle.load` and store it back in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('noise.pickle','rb') as read_file:\n",
    "    new_noise = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random noise lives! We retrieved the entire structure from file. Nice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Okay, but I don't use dictionaries... I use pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(np.random.uniform(-10,10, size=(100,4)), columns=['Yay','specific','column','names'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('my_dataframe.pickle', 'wb') as to_write:\n",
    "    pickle.dump(df, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('my_dataframe.pickle','rb') as read_file:\n",
    "    new_df = pickle.load(read_file)\n",
    "    \n",
    "new_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle is a great tool. One recommended way of using it is to make it an end point of every step in your process. Example:\n",
    "\n",
    "* I got my data! Nice. Pickle it and stop your \"getting the data\" notebook.\n",
    "* Load your data from pickle. Clean it. Save your clean data to a new pickle.\n",
    "* Load your cleaned_data pickle. Do analysis and visualize it.\n",
    "\n",
    "This can provide natural \"pick-up-where-I-left-off-but-before-I-broke-my-data\" points. It's a great way to control the flow of your data.\n",
    "\n",
    "#### Resources\n",
    "\n",
    "https://docs.python.org/3.7/library/pickle.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
